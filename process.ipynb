{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca4e777",
   "metadata": {},
   "source": [
    "# Movie Dialogue Analysis - Based on Three Star Wars Movies\n",
    "***This part is done by Yufei Zhang(25405381)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2617cbdd",
   "metadata": {},
   "source": [
    "## 1. Extract Star Wars movied data from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17166fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 42,\n",
       " 1115,\n",
       " 371,\n",
       "     movieID                                       title  year  rating  \\\n",
       " 337    m337          star wars: the empire strikes back  1982     8.0   \n",
       " 489    m489  star wars: episode vi - return of the jedi  1983     8.3   \n",
       " 529    m529                                   star wars  1977     8.8   \n",
       " \n",
       "         votes                                        genres  \n",
       " 337      42.0  ['animation' 'adventure' 'action' 'fantasy']  \n",
       " 489  215058.0     ['action' 'adventure' 'fantasy' 'sci-fi']  \n",
       " 529  326619.0     ['action' 'adventure' 'fantasy' 'sci-fi']  )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, re, unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "SCHEMAS = {\n",
    "    \"titles\": [\"movieID\",\"title\",\"year\",\"rating\",\"votes\",\"genres\"],\n",
    "    \"characters\": [\"characterID\",\"character\",\"movieID\",\"movie\",\"gender\",\"position\"],\n",
    "    \"lines\": [\"lineID\",\"characterID\",\"movieID\",\"character\",\"text\"],\n",
    "    \"conversations\": [\"character1ID\",\"character2ID\",\"movieID\",\"utteranceIDs\"],\n",
    "}\n",
    "\n",
    "def load_tsv(path: Path, names):\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=None, names=names, engine=\"python\", on_bad_lines=\"skip\")\n",
    "    for c in names:\n",
    "        if df[c].dtype == object:\n",
    "            df[c] = df[c].astype(str).str.strip().str.strip(\"'\").str.strip('\"')\n",
    "    return df\n",
    "\n",
    "def norm(s):\n",
    "    if not isinstance(s,str): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", s).lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "titles = load_tsv(\"movie_titles_metadata.tsv\", SCHEMAS[\"titles\"])\n",
    "characters = load_tsv(\"movie_characters_metadata.tsv\", SCHEMAS[\"characters\"])\n",
    "lines = load_tsv(\"movie_lines.tsv\", SCHEMAS[\"lines\"])\n",
    "convos = load_tsv(\"movie_conversations.tsv\", SCHEMAS[\"conversations\"])\n",
    "\n",
    "titles[\"n\"] = titles[\"title\"].map(norm)\n",
    "\n",
    "mask_iv_plain = (titles[\"n\"]==\"star wars\") & (titles[\"year\"].astype(str).str.contains(\"1977\"))\n",
    "mask_v  = titles[\"n\"].str.contains(\"empire strikes back\", na=False)\n",
    "mask_vi = titles[\"n\"].str.contains(\"return of the jedi\", na=False)\n",
    "\n",
    "tri = titles[mask_iv_plain | mask_v | mask_vi].copy()\n",
    "sw_ids = set(tri[\"movieID\"].astype(str))\n",
    "\n",
    "sw_movies = titles[titles[\"movieID\"].astype(str).isin(sw_ids)][[\"movieID\",\"title\",\"year\",\"rating\",\"votes\",\"genres\"]].drop_duplicates()\n",
    "sw_characters = characters[characters[\"movieID\"].astype(str).isin(sw_ids)].copy()\n",
    "sw_lines = lines[lines[\"movieID\"].astype(str).isin(sw_ids)].copy()\n",
    "sw_convos = convos[convos[\"movieID\"].astype(str).isin(sw_ids)].copy()\n",
    "\n",
    "sw_movies.to_csv(\"starwars_core/sw_movies.csv\", index=False, encoding=\"utf-8\")\n",
    "sw_characters.to_csv(\"starwars_core/sw_characters.csv\", index=False, encoding=\"utf-8\")\n",
    "sw_lines.to_csv(\"starwars_core/sw_lines.csv\", index=False, encoding=\"utf-8\")\n",
    "sw_convos.to_csv(\"starwars_core/sw_conversations.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "len(sw_movies), len(sw_characters), len(sw_lines), len(sw_convos), sw_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4bb982",
   "metadata": {},
   "source": [
    "# 2. Carry out data preprocessing and cleaning. \n",
    "Since some roles have no clear direction, such as the Blue Leader, we will delete them.\n",
    "\n",
    "***This part is done by Yufei Zhang(25405381)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4199764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files check:\n",
      " - ✅ starwars_core/sw_movies.csv\n",
      " - ✅ starwars_core/sw_characters.csv\n",
      " - ✅ starwars_core/sw_lines.csv\n",
      " - ✅ starwars_core/sw_conversations.csv\n"
     ]
    }
   ],
   "source": [
    "import os, time, pandas as pd\n",
    "\n",
    "CORE_DIR = \"starwars_core\"\n",
    "OUT_DIR  = \"starwars_filtered\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def ok(p): \n",
    "    return \"✅\" if os.path.exists(p) else \"❌\"\n",
    "\n",
    "print(\"Files check:\")\n",
    "print(\" -\", ok(f\"{CORE_DIR}/sw_movies.csv\"), f\"{CORE_DIR}/sw_movies.csv\")\n",
    "print(\" -\", ok(f\"{CORE_DIR}/sw_characters.csv\"), f\"{CORE_DIR}/sw_characters.csv\")\n",
    "print(\" -\", ok(f\"{CORE_DIR}/sw_lines.csv\"), f\"{CORE_DIR}/sw_lines.csv\")\n",
    "print(\" -\", ok(f\"{CORE_DIR}/sw_conversations.csv\"), f\"{CORE_DIR}/sw_conversations.csv\")\n",
    "\n",
    "t0 = time.time()\n",
    "def log(msg):\n",
    "    dt = time.time()-t0\n",
    "    print(f\"[{dt:6.1f}s] {msg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66eb5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buttons to control output\n",
    "MAKE_NETWORK   = True\n",
    "MAKE_WORDCLOUD = False   \n",
    "\n",
    "# having pictures for these characters\n",
    "avatar_whitelist = {\n",
    "    \"ackbar\": \"ackbar.png\",\n",
    "    \"admiral piett\": \"admiral_piett.png\",\n",
    "    \"ben kenobi\": \"ben_kenobi.png\",\n",
    "    \"biggs\": \"biggs.png\",\n",
    "    \"boushh\": \"boushh.png\",\n",
    "    \"c-3po\": \"c3po.png\",\n",
    "    \"chewie\": \"chewie.png\",\n",
    "    \"han\": \"han.png\",\n",
    "    \"lando\": \"lando.png\",\n",
    "    \"leia\": \"leia.png\",\n",
    "    \"luke\": \"luke.png\",\n",
    "    \"ninedenine\": \"ninedenine.png\",\n",
    "    \"owen\": \"owen.png\",\n",
    "    \"rieekan\": \"rieekan.png\",\n",
    "    \"vader\": \"vader.png\",\n",
    "    \"wedge\": \"wedge.png\",\n",
    "    \"yoda\": \"yoda.png\",\n",
    "}\n",
    "\n",
    "# aliases for character names\n",
    "aliases = {\n",
    "    \"threepio\": \"c-3po\",\n",
    "    \"piett\": \"admiral piett\",\n",
    "    \"darth vader\": \"vader\",\n",
    "    \"princess leia\": \"leia\",\n",
    "    \"lando calrissian\": \"lando\",\n",
    "    \"ben\": \"ben kenobi\",\n",
    "}\n",
    "\n",
    "import re\n",
    "def norm_name(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s).strip().lower())\n",
    "\n",
    "def canon_name(s: str) -> str:\n",
    "    n = norm_name(s)\n",
    "    return aliases.get(n, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.0s] Loading core tables (robust)...\n",
      "[   0.1s] titles=(3, 6), chars=(42, 6), lines=(1115, 5), convs=(371, 4)\n",
      "[   0.1s] convs columns: ['character1ID', 'character2ID', 'movieID', 'utteranceIDs']\n",
      "[   0.1s] Using utterances column: utteranceIDs\n",
      "[   0.1s] Sample parsed_utterances: ['L191961', 'L191962', 'L191963', 'L191964', 'L191965', 'L191966']\n",
      "[   0.1s] Whitelist characters (17): ['ackbar', 'admiral piett', 'ben kenobi', 'biggs', 'boushh', 'c-3po', 'chewie', 'han', 'lando', 'leia', 'luke', 'ninedenine', 'owen', 'rieekan', 'vader', 'wedge', 'yoda']\n",
      "[   0.1s] Filtered chars=(32, 7), lines=(1054, 6)\n"
     ]
    }
   ],
   "source": [
    "log(\"Loading core tables (robust)...\")\n",
    "import json, re\n",
    "\n",
    "# make sure to load sw_movies.csv or sw_titles.csv\n",
    "titles_path = None\n",
    "for nm in [\"sw_movies.csv\", \"sw_titles.csv\"]:\n",
    "    p = f\"{CORE_DIR}/{nm}\"\n",
    "    if os.path.exists(p):\n",
    "        titles_path = p\n",
    "        break\n",
    "if titles_path is None:\n",
    "    raise FileNotFoundError(\"Missing sw_movies.csv / sw_titles.csv in starwars_core/\")\n",
    "\n",
    "titles = pd.read_csv(titles_path)\n",
    "chars  = pd.read_csv(f\"{CORE_DIR}/sw_characters.csv\")\n",
    "lines  = pd.read_csv(f\"{CORE_DIR}/sw_lines.csv\")            # line_num already included\n",
    "convs  = pd.read_csv(f\"{CORE_DIR}/sw_conversations.csv\")\n",
    "\n",
    "log(f\"titles={titles.shape}, chars={chars.shape}, lines={lines.shape}, convs={convs.shape}\")\n",
    "log(f\"convs columns: {list(convs.columns)}\")\n",
    "\n",
    "# normalize character names\n",
    "chars[\"character_norm\"] = chars[\"character\"].map(canon_name).map(norm_name)\n",
    "lines[\"character_norm\"] = lines[\"character\"].map(canon_name).map(norm_name)\n",
    "\n",
    "# position already exists in chars\n",
    "def parse_utter_list(cell):\n",
    "    s = str(cell).strip().replace(\"'\", '\"')\n",
    "    s = re.sub(r\"\\[\\s*([^\\]]+)\\s*\\]\", lambda m: \"[\" + \",\".join(m.group(1).split()) + \"]\", s)\n",
    "    if not s.startswith(\"[\"):\n",
    "        return re.findall(r\"L\\d+\", s)\n",
    "    try:\n",
    "        raw = json.loads(s)\n",
    "        return [str(x).strip('\"') for x in raw]\n",
    "    except Exception:\n",
    "        return re.findall(r\"L\\d+\", s)\n",
    "\n",
    "# find utterances column\n",
    "utter_col = None\n",
    "for c in convs.columns:\n",
    "    lc = c.strip().lower()\n",
    "    if \"parsed\" in lc and \"utter\" in lc:\n",
    "        utter_col = c\n",
    "        break\n",
    "if utter_col is None:\n",
    "    for c in convs.columns:\n",
    "        lc = c.strip().lower()\n",
    "        if \"utter\" in lc:   # utterances\n",
    "            utter_col = c\n",
    "            break\n",
    "\n",
    "if utter_col is None:\n",
    "    raise KeyError(\"sw_conversations.csv missing utterances column\")\n",
    "\n",
    "# get parsed_utterances\n",
    "if \"parsed_utterances\" == utter_col:\n",
    "    # have parsed_utterances, but may be string, need to parse again\n",
    "    convs[\"parsed_utterances\"] = convs[utter_col].apply(parse_utter_list)\n",
    "else:\n",
    "    # just original utterances, need to parse\n",
    "    convs[\"parsed_utterances\"] = convs[utter_col].apply(parse_utter_list)\n",
    "\n",
    "log(f\"Using utterances column: {utter_col}\")\n",
    "sample = convs[\"parsed_utterances\"].iloc[0] if len(convs) else \"N/A\"\n",
    "log(f\"Sample parsed_utterances: {sample}\")\n",
    "\n",
    "# filter characters by whitelist\n",
    "keep_names = set(avatar_whitelist.keys())\n",
    "log(f\"Whitelist characters ({len(keep_names)}): {sorted(keep_names)}\")\n",
    "\n",
    "chars_keep = chars[chars[\"character_norm\"].isin(keep_names)].copy()\n",
    "lines_keep = lines[lines[\"character_norm\"].isin(keep_names)].copy()\n",
    "log(f\"Filtered chars={chars_keep.shape}, lines={lines_keep.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b43122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines_keep columns: ['lineID', 'characterID', 'movieID', 'character', 'text', 'character_norm', 'line_num']\n",
      "example：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lineID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>character_norm</th>\n",
       "      <th>line_num</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L191966</td>\n",
       "      <td>m337</td>\n",
       "      <td>vader</td>\n",
       "      <td>191966</td>\n",
       "      <td>And code the signal to my private chamber.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L191964</td>\n",
       "      <td>m337</td>\n",
       "      <td>vader</td>\n",
       "      <td>191964</td>\n",
       "      <td>Move this ship out of the asteroid field and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L191962</td>\n",
       "      <td>m337</td>\n",
       "      <td>vader</td>\n",
       "      <td>191962</td>\n",
       "      <td>The Emperor?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lineID movieID character_norm  line_num  \\\n",
       "0  L191966    m337          vader    191966   \n",
       "2  L191964    m337          vader    191964   \n",
       "4  L191962    m337          vader    191962   \n",
       "\n",
       "                                                text  \n",
       "0         And code the signal to my private chamber.  \n",
       "2  Move this ship out of the asteroid field and i...  \n",
       "4                                       The Emperor?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# normalize column names to lower case and strip spaces\n",
    "def normalize_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "lines = normalize_cols(lines)\n",
    "chars = normalize_cols(chars)\n",
    "convs = normalize_cols(convs)\n",
    "\n",
    "# make a mapping for lines table\n",
    "col_map_lines = {\n",
    "    \"lineid\": \"lineID\",\n",
    "    \"characterid\": \"characterID\",\n",
    "    \"movieid\": \"movieID\",\n",
    "    \"character\": \"character\",\n",
    "    \"text\": \"text\",\n",
    "    \"line_num\": \"line_num\",   # if exists\n",
    "}\n",
    "# restore desired casing (only for code convenience; can use all lower case too)\n",
    "def remap(df, cmap):\n",
    "    for k, v in list(cmap.items()):\n",
    "        if k in df.columns and v not in df.columns:\n",
    "            df.rename(columns={k: v}, inplace=True)\n",
    "    return df\n",
    "\n",
    "lines = remap(lines, col_map_lines)\n",
    "\n",
    "# if line_num not exists, try to extract from lineID\n",
    "if \"line_num\" not in lines.columns:\n",
    "    def line_num_from_id(lid):\n",
    "        m = re.search(r\"(\\d+)\", str(lid))\n",
    "        return int(m.group(1)) if m else None\n",
    "    lines[\"line_num\"] = lines[\"lineID\"].apply(line_num_from_id)\n",
    "\n",
    "# fill character_norm if missing\n",
    "if \"character_norm\" not in lines.columns:\n",
    "    lines[\"character_norm\"] = lines[\"character\"].map(canon_name).map(norm_name)\n",
    "\n",
    "# filter by whitelist\n",
    "keep_names = set(avatar_whitelist.keys())\n",
    "lines_keep = lines[lines[\"character_norm\"].isin(keep_names)].copy()\n",
    "\n",
    "# check required columns\n",
    "missing_cols = [c for c in [\"lineID\",\"movieID\",\"line_num\",\"character_norm\"] if c not in lines_keep.columns]\n",
    "if missing_cols:\n",
    "    raise KeyError(f\"lines_keep missing：{missing_cols}；please check the previous cell.\")\n",
    "\n",
    "# make a quick snapshot\n",
    "print(\"lines_keep columns:\", list(lines_keep.columns))\n",
    "print(\"example：\")\n",
    "display(lines_keep.head(3)[[\"lineID\",\"movieID\",\"character_norm\",\"line_num\",\"text\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f042d2",
   "metadata": {},
   "source": [
    "# 3. Build the nodes and edges of conversations\n",
    "***This part is done by Yufei Zhang(25405381)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb9477b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 371/371 [00:00<00:00, 185579.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.2s] events_df=(655, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import re, json\n",
    "import pandas as pd\n",
    "\n",
    "# normalize column names (strip spaces only, keep case)\n",
    "def norm_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "convs = norm_cols(convs)\n",
    "\n",
    "# find movieID column\n",
    "movie_col = None\n",
    "for c in convs.columns:\n",
    "    lc = c.lower()\n",
    "    if lc in (\"movieid\", \"movie_id\", \"movie\"):\n",
    "        movie_col = c\n",
    "        break\n",
    "if movie_col is None:\n",
    "    raise KeyError(f\"无法在 sw_conversations.csv 中识别电影列名，现有列：{list(convs.columns)}\")\n",
    "\n",
    "# rename to movieID if needed\n",
    "if movie_col != \"movieID\":\n",
    "    convs = convs.rename(columns={movie_col: \"movieID\"})\n",
    "\n",
    "# deal with parsed_utterances column\n",
    "def parse_utter_list(cell):\n",
    "    s = str(cell).strip().replace(\"'\", '\"')\n",
    "    s = re.sub(r\"\\[\\s*([^\\]]+)\\s*\\]\", lambda m: \"[\" + \",\".join(m.group(1).split()) + \"]\", s)\n",
    "    if not s.startswith(\"[\"):\n",
    "        return re.findall(r\"L\\d+\", s)\n",
    "    try:\n",
    "        raw = json.loads(s)\n",
    "        return [str(x).strip('\"') for x in raw]\n",
    "    except Exception:\n",
    "        return re.findall(r\"L\\d+\", s)\n",
    "\n",
    "if \"parsed_utterances\" not in convs.columns:\n",
    "    # try to find utterances column\n",
    "    utter_col = None\n",
    "    for c in convs.columns:\n",
    "        if \"utter\" in c.lower():\n",
    "            utter_col = c\n",
    "            break\n",
    "    if utter_col is None:\n",
    "        raise KeyError(f\"找不到 utterances 列，现有列：{list(convs.columns)}\")\n",
    "    convs[\"parsed_utterances\"] = convs[utter_col].apply(parse_utter_list)\n",
    "else:\n",
    "    \n",
    "    convs[\"parsed_utterances\"] = convs[\"parsed_utterances\"].apply(parse_utter_list)\n",
    "\n",
    "# make sure lines_keep has required columns\n",
    "required = {\"lineID\",\"movieID\",\"character_norm\",\"line_num\"}\n",
    "missing = required - set(lines_keep.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"lines_keep 缺列 {missing}，请检查前一单元格。\")\n",
    "\n",
    "line_lookup = lines_keep.set_index(\"lineID\")[[\"movieID\",\"character_norm\",\"line_num\"]].to_dict(orient=\"index\")\n",
    "\n",
    "# generate events (use column unpacking to avoid attribute access)\n",
    "events = []\n",
    "total_rows = len(convs)\n",
    "for mov, utts in tqdm(convs[[\"movieID\",\"parsed_utterances\"]].itertuples(index=False, name=None), total=total_rows):\n",
    "    prev = None\n",
    "    for lid in utts:\n",
    "        info = line_lookup.get(lid)\n",
    "        if not info:\n",
    "            continue\n",
    "        spk = info[\"character_norm\"]\n",
    "        t   = info[\"line_num\"]\n",
    "        if prev is not None and spk != prev:\n",
    "            a, b = sorted([prev, spk])\n",
    "            events.append({\"movieID\": mov, \"t\": t, \"src\": a, \"dst\": b})\n",
    "        prev = spk\n",
    "\n",
    "events_df = pd.DataFrame(events)\n",
    "log(f\"events_df={events_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "536a1dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.2s] edges_total=(40, 4), edges_time=(655, 5)\n"
     ]
    }
   ],
   "source": [
    "# edge weights (total)\n",
    "edges_total = events_df.groupby([\"movieID\",\"src\",\"dst\"]).size().reset_index(name=\"weight\")\n",
    "\n",
    "# cumulative edges (time)\n",
    "def cumulative_edges(df):\n",
    "    df = df.sort_values(\"t\")\n",
    "    cum = defaultdict(int)\n",
    "    out = []\n",
    "    for _, r in df.iterrows():\n",
    "        key = (r[\"src\"], r[\"dst\"])\n",
    "        cum[key] += 1\n",
    "        out.append({\"movieID\": r[\"movieID\"], \"t\": r[\"t\"], \"src\": r[\"src\"], \"dst\": r[\"dst\"], \"weight\": cum[key]})\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "edges_time = (pd.concat([cumulative_edges(g) for _, g in events_df.groupby(\"movieID\")], ignore_index=True)\n",
    "              if len(events_df) else pd.DataFrame(columns=[\"movieID\",\"t\",\"src\",\"dst\",\"weight\"]))\n",
    "\n",
    "log(f\"edges_total={edges_total.shape}, edges_time={edges_time.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83e61fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the time that characters show：\n",
      "character_norm\n",
      "ackbar             6\n",
      "admiral piett      9\n",
      "ben kenobi        93\n",
      "biggs              5\n",
      "boushh             3\n",
      "c-3po             60\n",
      "chewie            17\n",
      "han              248\n",
      "lando             70\n",
      "leia             177\n",
      "luke             232\n",
      "ninedenine         4\n",
      "owen               4\n",
      "rieekan           12\n",
      "vader             64\n",
      "wedge              6\n",
      "yoda              44\n",
      "Name: count, dtype: int32\n",
      "\n",
      "utterance mapping hitted: 94.53%  (hit 1054 / sum 1115)\n",
      "miss lineID： ['L191961', 'L191963', 'L191965', 'L191995', 'L191997', 'L191999', 'L192001', 'L192006', 'L192008', 'L192010']\n",
      "\n",
      "conversations example：\n",
      "movieID: m337\n",
      "parsed_utterances (first 10): ['L191961', 'L191962', 'L191963', 'L191964', 'L191965', 'L191966']\n"
     ]
    }
   ],
   "source": [
    "# analysis checks\n",
    "from collections import Counter\n",
    "\n",
    "# if avatar whitelist characters are really in lines_keep?\n",
    "print(\"the time that characters show：\")\n",
    "print(lines_keep[\"character_norm\"].value_counts().reindex(sorted(keep_names)).fillna(0).astype(int))\n",
    "\n",
    "# number of utterances that can be mapped to line_lookup\n",
    "total_utts = 0\n",
    "hit_utts = 0\n",
    "miss_examples = []\n",
    "for mov, utts in convs[[\"movieID\",\"parsed_utterances\"]].itertuples(index=False, name=None):\n",
    "    total_utts += len(utts)\n",
    "    for lid in utts:\n",
    "        if lid in line_lookup:\n",
    "            hit_utts += 1\n",
    "        elif len(miss_examples) < 10:\n",
    "            miss_examples.append(lid)\n",
    "\n",
    "hit_rate = hit_utts / total_utts if total_utts else 0\n",
    "print(f\"\\nutterance mapping hitted: {hit_rate:.2%}  (hit {hit_utts} / sum {total_utts})\")\n",
    "if miss_examples:\n",
    "    print(\"miss lineID：\", miss_examples)\n",
    "\n",
    "# look at a sample conversation\n",
    "if len(convs):\n",
    "    sample = convs.iloc[0]\n",
    "    print(\"\\nconversations example：\")\n",
    "    print(\"movieID:\", sample[\"movieID\"])\n",
    "    print(\"parsed_utterances (first 10):\", sample[\"parsed_utterances\"][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44cdef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars_keep columns: ['characterID', 'character', 'movieID', 'movie', 'gender', 'position', 'character_norm']\n",
      "[   0.2s] done：nodes.csv / edges_total.csv / edges_time.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>character</th>\n",
       "      <th>movie</th>\n",
       "      <th>gender</th>\n",
       "      <th>credit_pos</th>\n",
       "      <th>faction</th>\n",
       "      <th>avatar_png</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m337</td>\n",
       "      <td>admiral piett</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Galactic Empire</td>\n",
       "      <td>admiral_piett.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m337</td>\n",
       "      <td>ben kenobi</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jedi</td>\n",
       "      <td>ben_kenobi.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>m337</td>\n",
       "      <td>c-3po</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Droid</td>\n",
       "      <td>c3po.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m337</td>\n",
       "      <td>chewie</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rebel Alliance</td>\n",
       "      <td>chewie.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>m337</td>\n",
       "      <td>han</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rebel Alliance</td>\n",
       "      <td>han.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>m337</td>\n",
       "      <td>lando</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rebel Alliance</td>\n",
       "      <td>lando.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>m337</td>\n",
       "      <td>leia</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rebel Alliance</td>\n",
       "      <td>leia.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>m337</td>\n",
       "      <td>luke</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jedi</td>\n",
       "      <td>luke.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>m337</td>\n",
       "      <td>rieekan</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rebel Alliance</td>\n",
       "      <td>rieekan.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>m337</td>\n",
       "      <td>vader</td>\n",
       "      <td>star wars: the empire strikes back</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Galactic Empire</td>\n",
       "      <td>vader.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID      character                               movie gender  \\\n",
       "1     m337  admiral piett  star wars: the empire strikes back      ?   \n",
       "2     m337     ben kenobi  star wars: the empire strikes back      ?   \n",
       "13    m337          c-3po  star wars: the empire strikes back      ?   \n",
       "3     m337         chewie  star wars: the empire strikes back      ?   \n",
       "7     m337            han  star wars: the empire strikes back      M   \n",
       "8     m337          lando  star wars: the empire strikes back      m   \n",
       "9     m337           leia  star wars: the empire strikes back      F   \n",
       "10    m337           luke  star wars: the empire strikes back      m   \n",
       "12    m337        rieekan  star wars: the empire strikes back      ?   \n",
       "14    m337          vader  star wars: the empire strikes back      ?   \n",
       "\n",
       "    credit_pos          faction         avatar_png  \n",
       "1          NaN  Galactic Empire  admiral_piett.png  \n",
       "2          NaN             Jedi     ben_kenobi.png  \n",
       "13         NaN            Droid           c3po.png  \n",
       "3          NaN   Rebel Alliance         chewie.png  \n",
       "7          NaN   Rebel Alliance            han.png  \n",
       "8          NaN   Rebel Alliance          lando.png  \n",
       "9          NaN   Rebel Alliance           leia.png  \n",
       "10         NaN             Jedi           luke.png  \n",
       "12         NaN   Rebel Alliance        rieekan.png  \n",
       "14         NaN  Galactic Empire          vader.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build nodes table\n",
    "import pandas as pd\n",
    "\n",
    "def ensure_col(df, name, fill=None):\n",
    "    if name not in df.columns:\n",
    "        df[name] = fill\n",
    "    return df\n",
    "\n",
    "# chars_keep from previous cells\n",
    "print(\"chars_keep columns:\", list(chars_keep.columns))\n",
    "\n",
    "# fill required columns\n",
    "for c in [\"movieID\",\"character_norm\",\"movie\",\"gender\",\"credit_pos\"]:\n",
    "    chars_keep = ensure_col(chars_keep, c, None)\n",
    "\n",
    "# credit_pos coerce to numeric\n",
    "chars_keep[\"credit_pos\"] = pd.to_numeric(chars_keep[\"credit_pos\"], errors=\"coerce\")\n",
    "\n",
    "# build nodes\n",
    "nodes = (\n",
    "    chars_keep\n",
    "    .sort_values([\"movieID\",\"character_norm\",\"credit_pos\"], na_position=\"last\")\n",
    "    .drop_duplicates(subset=[\"movieID\",\"character_norm\"])\n",
    "    [[\"movieID\",\"character_norm\",\"movie\",\"gender\",\"credit_pos\"]]\n",
    "    .rename(columns={\"character_norm\":\"character\"})\n",
    ")\n",
    "\n",
    "# the faction mapping\n",
    "faction_map = {\n",
    "    \"ackbar\": \"Rebel Alliance\",\n",
    "    \"admiral piett\": \"Galactic Empire\",\n",
    "    \"ben kenobi\": \"Jedi\",\n",
    "    \"biggs\": \"Rebel Alliance\",\n",
    "    \"boushh\": \"Unknown\",\n",
    "    \"c-3po\": \"Droid\",\n",
    "    \"chewie\": \"Rebel Alliance\",\n",
    "    \"han\": \"Rebel Alliance\",\n",
    "    \"lando\": \"Rebel Alliance\",\n",
    "    \"leia\": \"Rebel Alliance\",\n",
    "    \"luke\": \"Jedi\",\n",
    "    \"ninedenine\": \"Unknown\",\n",
    "    \"owen\": \"Unknown\",\n",
    "    \"rieekan\": \"Rebel Alliance\",\n",
    "    \"vader\": \"Galactic Empire\",\n",
    "    \"wedge\": \"Rebel Alliance\",\n",
    "    \"yoda\": \"Jedi\",\n",
    "}\n",
    "nodes[\"faction\"] = nodes[\"character\"].map(lambda x: faction_map.get(x, \"Unknown\"))\n",
    "\n",
    "# picture filenames\n",
    "nodes[\"avatar_png\"] = nodes[\"character\"].map(lambda n: avatar_whitelist.get(n))\n",
    "\n",
    "# save nodes and edges\n",
    "nodes.to_csv(f\"{OUT_DIR}/nodes.csv\", index=False)\n",
    "\n",
    "# prevent missing edges tables\n",
    "if 'edges_total' not in globals():\n",
    "    edges_total = pd.DataFrame(columns=[\"movieID\",\"src\",\"dst\",\"weight\"])\n",
    "if 'edges_time' not in globals():\n",
    "    edges_time = pd.DataFrame(columns=[\"movieID\",\"t\",\"src\",\"dst\",\"weight\"])\n",
    "\n",
    "edges_total.to_csv(f\"{OUT_DIR}/edges_total.csv\", index=False)\n",
    "edges_time.to_csv(f\"{OUT_DIR}/edges_time.csv\", index=False)\n",
    "\n",
    "log(\"done：nodes.csv / edges_total.csv / edges_time.csv\")\n",
    "display(nodes.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf5db9",
   "metadata": {},
   "source": [
    "# 4. Build the emotional visualization library and interactive website\n",
    "***This part is done by Yufei Zhang(25405381)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afcf1a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Whitelist] avater: 17 / 17\n",
      "sum line：1115，whitelist line：897，whitelist avater：15\n",
      "[Rebuilt] whitelist lines = 897  | characters with lines = 15\n"
     ]
    }
   ],
   "source": [
    "import re, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "nodes = pd.read_csv(\"starwars_filtered/nodes.csv\")\n",
    "edges_time = pd.read_csv(\"starwars_filtered/edges_time.csv\")\n",
    "edges_total = pd.read_csv(\"starwars_filtered/edges_total.csv\")\n",
    "sw_chars = pd.read_csv(\"starwars_core/sw_characters.csv\")\n",
    "sw_lines = pd.read_csv(\"starwars_core/sw_lines.csv\")\n",
    "sw_movies = pd.read_csv(\"starwars_core/sw_movies.csv\")\n",
    "\n",
    "# normalize column names\n",
    "for df in (nodes, edges_time, edges_total, sw_chars, sw_lines, sw_movies):\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "# avatar mapping\n",
    "AVATAR_DIR = Path(\"assets/avatars\")\n",
    "def norm_key(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9_]+\", \"\", str(s).lower().strip().replace(\" \", \"_\"))\n",
    "\n",
    "avatar_index = {}\n",
    "if AVATAR_DIR.exists():\n",
    "    for p in AVATAR_DIR.glob(\"*.png\"):\n",
    "        avatar_index[norm_key(p.stem)] = f\"/assets/avatars/{p.name}\"\n",
    "\n",
    "\n",
    "# nodes processing\n",
    "if \"character\" not in nodes.columns:\n",
    "    # normalize common alternative column names\n",
    "    for alt in [\"name\", \"label\", \"char\", \"speaker\"]:\n",
    "        if alt in nodes.columns:\n",
    "            nodes.rename(columns={alt: \"character\"}, inplace=True)\n",
    "            break\n",
    "assert \"character\" in nodes.columns, \"nodes.csv need one of the colomn（character/name/label/char/speaker ）\"\n",
    "\n",
    "nodes[\"character\"] = nodes[\"character\"].astype(str)\n",
    "nodes[\"id\"] = nodes.get(\"id\", pd.Series(index=nodes.index, dtype=object))\n",
    "if nodes[\"id\"].isna().all():\n",
    "    nodes[\"id\"] = nodes[\"character\"].map(norm_key)\n",
    "\n",
    "# if id exists but not string, convert to string\n",
    "nodes = nodes.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "\n",
    "# if no avatar_png column, create one\n",
    "if \"avatar_png\" not in nodes.columns:\n",
    "    nodes[\"avatar_png\"] = None\n",
    "\n",
    "avatar_index = {}\n",
    "if AVATAR_DIR.exists():\n",
    "    for p in AVATAR_DIR.glob(\"*.png\"):\n",
    "        avatar_index[norm_key(p.stem)] = f\"/assets/avatars/{p.name}\"\n",
    "\n",
    "def fill_avatar(row):\n",
    "    cur = str(row.get(\"avatar_png\") or \"\").strip()\n",
    "    if cur:\n",
    "        return cur\n",
    "    return avatar_index.get(row[\"id\"], None)\n",
    "\n",
    "nodes[\"avatar_png\"] = nodes.apply(fill_avatar, axis=1)\n",
    "\n",
    "# whitelist: must have avatar\n",
    "nodes_whitelist = nodes[nodes[\"avatar_png\"].notna() & (nodes[\"avatar_png\"].astype(str) != \"\")]\n",
    "nodes_whitelist = nodes_whitelist.drop_duplicates(subset=[\"id\"]).copy()\n",
    "nodes_whitelist[\"id_norm\"] = nodes_whitelist[\"id\"]  \n",
    "whitelist_ids = set(nodes_whitelist[\"id\"].astype(str))\n",
    "\n",
    "print(f\"[Whitelist] avater: {len(nodes_whitelist)} / {len(nodes)}\")\n",
    "\n",
    "# make sure sw_lines has 'character' column\n",
    "sw_lines = sw_lines.copy()\n",
    "if \"character\" not in sw_lines.columns or sw_lines[\"character\"].isna().all():\n",
    "    cid_col = \"characterid\" if \"characterid\" in sw_characters.columns else (\n",
    "              \"character_id\" if \"character_id\" in sw_characters.columns else None)\n",
    "    assert cid_col is not None, \"sw_characters.csv 需要 characterid/character_id 以把台词里的ID映射到姓名\"\n",
    "    id2name = dict(zip(sw_characters[cid_col].astype(str), sw_characters[\"character\"].astype(str)))\n",
    "    key_in_lines = \"character_id\" if \"character_id\" in sw_lines.columns else (\"characterid\" if \"characterid\" in sw_lines.columns else None)\n",
    "    assert key_in_lines is not None, \"sw_lines.csv 缺少 character 或 character_id/characterid\"\n",
    "    sw_lines[\"character\"] = sw_lines[key_in_lines].astype(str).map(id2name)\n",
    "\n",
    "# line_num\n",
    "if \"line_num\" not in sw_lines.columns:\n",
    "    def line_num_from_id(x):\n",
    "        m = re.search(r\"(\\d+)\", str(x));  return int(m.group(1)) if m else None\n",
    "    sw_lines[\"line_num\"] = sw_lines[\"lineid\"].map(line_num_from_id) if \"lineid\" in sw_lines.columns else sw_lines.reset_index().index\n",
    "\n",
    "sw_lines[\"char_norm\"] = sw_lines[\"character\"].astype(str).map(norm_key)\n",
    "norm2id = dict(zip(nodes_whitelist[\"id_norm\"], nodes_whitelist[\"id\"].astype(str)))\n",
    "sw_lines[\"character_id\"] = sw_lines[\"char_norm\"].map(norm2id)\n",
    "\n",
    "# just whitelist lines\n",
    "lines_whitelist = sw_lines[sw_lines[\"character_id\"].notna()].copy()\n",
    "lines_whitelist[\"line_num\"] = pd.to_numeric(lines_whitelist[\"line_num\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"sum line：{len(sw_lines)}，whitelist line：{len(lines_whitelist)}，whitelist avater：{lines_whitelist['character_id'].nunique()}\")\n",
    "\n",
    "# fill sentiment (offline)\n",
    "POS = {\"good\",\"great\",\"excellent\",\"love\",\"like\",\"hope\",\"friend\",\"happy\",\"joy\",\"win\",\"calm\",\"safe\",\"brave\",\"peace\",\"trust\",\"support\"}\n",
    "NEG = {\"bad\",\"terrible\",\"awful\",\"hate\",\"kill\",\"fear\",\"anger\",\"war\",\"enemy\",\"sad\",\"cry\",\"hurt\",\"lose\",\"pain\",\"threat\",\"betray\",\"death\",\"dark\"}\n",
    "\n",
    "def classify_sentiment_offline(text: str):\n",
    "    t = re.sub(r\"[^a-zA-Z']+\", \" \", str(text)).lower().split()\n",
    "    pos = sum(1 for w in t if w in POS); neg = sum(1 for w in t if w in NEG)\n",
    "    total = pos + neg\n",
    "    comp = 0.0 if total==0 else (pos-neg)/total\n",
    "    lab = \"pos\" if comp>0.05 else (\"neg\" if comp<-0.05 else \"neu\")\n",
    "    return lab, comp\n",
    "\n",
    "if not lines_whitelist.empty:\n",
    "    sent_df = lines_whitelist[\"text\"].astype(str).apply(\n",
    "        lambda t: pd.Series(classify_sentiment_offline(t), index=[\"sent_label\",\"compound\"])\n",
    "    )\n",
    "    lines_whitelist = pd.concat([lines_whitelist, sent_df], axis=1)\n",
    "\n",
    "assert \"id\" in nodes.columns and \"character\" in nodes.columns, \"nodes.csv need: id, character\"\n",
    "nodes[\"id\"] = nodes[\"id\"].astype(str)\n",
    "nodes[\"character\"] = nodes[\"character\"].astype(str)\n",
    "\n",
    "if \"avatar_png\" not in nodes.columns:\n",
    "    nodes[\"avatar_png\"] = None\n",
    "\n",
    "def fill_avatar(row):\n",
    "    if pd.notna(row.get(\"avatar_png\")) and str(row[\"avatar_png\"]).strip():\n",
    "        return row[\"avatar_png\"]\n",
    "    k = norm_key(row[\"id\"])  # make sure key is normalized\n",
    "    return avatar_index.get(k, None)\n",
    "\n",
    "nodes[\"avatar_png\"] = nodes.apply(fill_avatar, axis=1)\n",
    "\n",
    "# whitelist: must have avatar\n",
    "nodes_whitelist = nodes[nodes[\"avatar_png\"].notna() & (nodes[\"avatar_png\"].astype(str) != \"\")]\n",
    "nodes_whitelist = nodes_whitelist.drop_duplicates(subset=[\"id\"]).copy()\n",
    "nodes_whitelist[\"id_norm\"] = nodes_whitelist[\"id\"].astype(str)  \n",
    "whitelist_set = set(nodes_whitelist[\"id_norm\"])\n",
    "\n",
    "# make sure sw_lines has 'character' column\n",
    "sw_lines2 = sw_lines.copy()\n",
    "if \"character\" not in sw_lines2.columns or sw_lines2[\"character\"].isna().all():\n",
    "    cid_col_chars = \"characterid\" if \"characterid\" in sw_chars.columns else (\n",
    "        \"character_id\" if \"character_id\" in sw_chars.columns else None\n",
    "    )\n",
    "    assert cid_col_chars is not None, \"sw_characters.csv 需要 characterid/character_id 用于ID→姓名映射\"\n",
    "    id2name = dict(zip(sw_chars[cid_col_chars].astype(str), sw_chars[\"character\"].astype(str)))\n",
    "\n",
    "    key_in_lines = \"character_id\" if \"character_id\" in sw_lines2.columns else (\n",
    "        \"characterid\" if \"characterid\" in sw_lines2.columns else None\n",
    "    )\n",
    "    assert key_in_lines is not None, \"sw_lines.csv 缺少 character 或 character_id/characterid\"\n",
    "    sw_lines2[\"character\"] = sw_lines2[key_in_lines].astype(str).map(id2name)\n",
    "\n",
    "sw_lines2[\"char_key\"] = sw_lines2[\"character\"].astype(str).map(norm_key)\n",
    "\n",
    "wl = sw_lines2[sw_lines2[\"char_key\"].isin(whitelist_set)].copy()\n",
    "\n",
    "if \"line_num\" not in wl.columns:\n",
    "    def line_num_from_id(x):\n",
    "        m = re.search(r\"(\\d+)\", str(x))\n",
    "        return int(m.group(1)) if m else None\n",
    "    wl[\"line_num\"] = wl[\"lineid\"].map(line_num_from_id) if \"lineid\" in wl.columns else wl.reset_index().index\n",
    "\n",
    "wl[\"line_num\"] = pd.to_numeric(wl[\"line_num\"], errors=\"coerce\")\n",
    "wl[\"text\"] = wl.get(\"text\", \"\").astype(str)\n",
    "\n",
    "# only keep needed columns\n",
    "cols_keep = []\n",
    "for c in [\"movieid\",\"lineid\",\"line_num\",\"character\",\"text\",\"sent_label\",\"compound\",\"char_key\"]:\n",
    "    if c in wl.columns: cols_keep.append(c)\n",
    "lines_whitelist = wl.loc[:, cols_keep].copy()\n",
    "\n",
    "# de-duplicate columns if any\n",
    "lines_whitelist = lines_whitelist.loc[:, ~lines_whitelist.columns.duplicated(keep=\"last\")]\n",
    "\n",
    "# rebuild char2lines\n",
    "char2lines = {\n",
    "    key: df.sort_values(\"line_num\").reset_index(drop=True)\n",
    "    for key, df in lines_whitelist.groupby(\"char_key\")\n",
    "}\n",
    "\n",
    "print(f\"[Rebuilt] whitelist lines = {len(lines_whitelist)}  | characters with lines = {len(char2lines)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "241fb8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] factions (unique): ['Droid', 'Galactic Empire', 'Jedi', 'Rebel Alliance', 'Unknown']\n",
      "[INFO] movie_ids: ['m337', 'm489', 'm529'] (titles available: 3)\n",
      "Running at http://127.0.0.1:63330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\dash\\dash.py:556: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:63330/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-36 (run):\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 788, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\retrying.py\", line 55, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\retrying.py\", line 289, in call\n",
      "    raise attempt.get()\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\retrying.py\", line 326, in get\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\retrying.py\", line 273, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\jupyter_dash\\jupyter_app.py\", line 305, in run\n",
      "    super_run_server(**kwargs)\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\dash\\dash.py\", line 2277, in run_server\n",
      "    self.run(*args, **kwargs)\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\dash\\dash.py\", line 2168, in run\n",
      "    jupyter_dash.run_app(\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\dash\\_jupyter.py\", line 404, in run_app\n",
      "    raise final_error\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\dash\\_jupyter.py\", line 396, in run_app\n",
      "    JupyterDash._display_in_jupyter(\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\dash\\_jupyter.py\", line 422, in _display_in_jupyter\n",
      "    display(IFrame(dashboard_url, width, height))\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\IPython\\core\\display_functions.py\", line 285, in display\n",
      "    publish_display_data(data=format_dict, metadata=md_dict, **kwargs)\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\IPython\\core\\display_functions.py\", line 73, in publish_display_data\n",
      "    display_pub.publish(\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 135, in publish\n",
      "    msg = self.session.msg(msg_type, json_clean(content), parent=self.parent_header)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\Anaconda\\envs\\starwars-net\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 69, in parent_header\n",
      "    return self._parent_header.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "LookupError: <ContextVar name='parent_header' at 0x000001B776C50860>\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Final Cell — factions from nodes.csv + movie titles in dropdown\n",
    "# ===================================================\n",
    "from pathlib import Path\n",
    "import re, socket\n",
    "import pandas as pd\n",
    "from jupyter_dash import JupyterDash, jupyter_app\n",
    "from dash import Dash, html, dcc, Input, Output, State\n",
    "import dash_cytoscape as cyto\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "AVATAR_DIR = Path(\"assets/avatars\")\n",
    "BG_COLOR   = \"#0b0f19\"\n",
    "\n",
    "# key: normalized faction name; value: color hex\n",
    "DEFAULT_FACTION_COLORS = {\n",
    "    \"rebellion\":   \"#4ade80\",\n",
    "    \"rebel\":       \"#4ade80\",\n",
    "    \"resistance\":  \"#4ade80\",\n",
    "    \"empire\":      \"#f87171\",\n",
    "    \"imperial\":    \"#f87171\",\n",
    "    \"jedi\":        \"#60a5fa\",\n",
    "    \"sith\":        \"#f43f5e\",\n",
    "    \"smuggler\":    \"#fbbf24\",\n",
    "    \"bounty_hunter\": \"#fb7185\",\n",
    "    \"droid\":       \"#22d3ee\",\n",
    "    \"neutral\":     \"#a78bfa\",\n",
    "    \"first_order\": \"#f471b5\"\n",
    "}\n",
    "\n",
    "# reusable color palette\n",
    "PALETTE = [\n",
    "    \"#22d3ee\", \"#a78bfa\", \"#f59e0b\", \"#34d399\", \"#60a5fa\",\n",
    "    \"#fb7185\", \"#f472b6\", \"#93c5fd\", \"#fbbf24\", \"#10b981\",\n",
    "    \"#f43f5e\", \"#86efac\", \"#fda4af\", \"#d8b4fe\", \"#7dd3fc\"\n",
    "]\n",
    "\n",
    "def norm_key(s:str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s).strip().lower())\n",
    "\n",
    "def natural_key(s:str):\n",
    "    return [int(t) if t.isdigit() else t for t in re.split(r'(\\d+)', str(s))]\n",
    "\n",
    "# data copies\n",
    "_nodes = nodes.copy()\n",
    "_edges = edges_total.copy()\n",
    "\n",
    "if \"id\" not in _nodes.columns and \"character\" in _nodes.columns:\n",
    "    _nodes[\"id\"] = _nodes[\"character\"]\n",
    "\n",
    "_nodes[\"id_norm\"] = _nodes[\"id\"].astype(str).map(norm_key)\n",
    "if \"character\" not in _nodes.columns:\n",
    "    _nodes[\"character\"] = _nodes[\"id\"]\n",
    "\n",
    "for c in (\"src\",\"dst\"):\n",
    "    _edges[c] = _edges[c].astype(str).map(norm_key)\n",
    "\n",
    "if \"weight\" not in _edges.columns:\n",
    "    _edges[\"weight\"] = 1\n",
    "if \"movieid\" not in _edges.columns:\n",
    "    _edges[\"movieid\"] = \"\"   \n",
    "\n",
    "# user override factions\n",
    "def load_nodes_override():\n",
    "    for fn in [\"nodes.csv\", \"proj/nodes.csv\", \"starwars_filtered/nodes.csv\"]:\n",
    "        p = Path(fn)\n",
    "        if p.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(p)\n",
    "                return df\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "override = load_nodes_override()\n",
    "override_map = {}\n",
    "if override is not None:\n",
    "    # use \"id\" or \"character\" as key\n",
    "    key_col = \"id\" if \"id\" in override.columns else \\\n",
    "              (\"character\" if \"character\" in override.columns else None)\n",
    "    fac_col = \"faction\" if \"faction\" in override.columns else None\n",
    "    if key_col and fac_col:\n",
    "        odf = override[[key_col, fac_col]].copy()\n",
    "        odf[\"id_norm\"] = odf[key_col].astype(str).map(norm_key)\n",
    "        for _, r in odf.iterrows():\n",
    "            kid = r[\"id_norm\"]\n",
    "            fct = str(r[fac_col]).strip()\n",
    "            if kid and fct:\n",
    "                override_map[kid] = fct\n",
    "\n",
    "# build node_map\n",
    "node_map = {}\n",
    "for _, r in _nodes.iterrows():\n",
    "    kid = r[\"id_norm\"]\n",
    "    if kid not in node_map:\n",
    "        node_map[kid] = {\n",
    "            \"id_norm\": kid,\n",
    "            \"label\": str(r.get(\"character\", r.get(\"id\", kid))),\n",
    "            \"avatar_png\": str(r.get(\"avatar_png\", \"\") or \"\"),\n",
    "            \"faction\": str(r.get(\"faction\", \"\") or \"\")\n",
    "        }\n",
    "# apply overrides\n",
    "for kid, fac in override_map.items():\n",
    "    if kid in node_map:\n",
    "        node_map[kid][\"faction\"] = fac\n",
    "\n",
    "edge_ids = set(_edges[\"src\"].tolist() + _edges[\"dst\"].tolist())\n",
    "for mid in edge_ids:\n",
    "    if mid not in node_map:\n",
    "        node_map[mid] = {\"id_norm\": mid, \"label\": mid, \"avatar_png\": \"\", \"faction\": \"\"}\n",
    "\n",
    "\n",
    "def load_movie_titles_from_csv():\n",
    "    candidates = [\n",
    "        r\"E:\\AIDM\\AIDM7330_programming\\proj\\starwars_core\\sw_movies.csv\",\n",
    "        \"starwars_core/sw_movies.csv\",\n",
    "        \"proj/starwars_core/sw_movies.csv\",\n",
    "    ]\n",
    "    for fp in candidates:\n",
    "        p = Path(fp)\n",
    "        if p.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(p)\n",
    "                # normalize columns\n",
    "                df.columns = [c.lower() for c in df.columns]\n",
    "                if {\"movieid\",\"title\"} <= set(df.columns):\n",
    "                    # use str keys\n",
    "                    mp = {str(r[\"movieid\"]): str(r[\"title\"]).strip().title()\n",
    "                          for _, r in df.iterrows()}\n",
    "                    return mp\n",
    "            except Exception:\n",
    "                pass\n",
    "    return {}\n",
    "\n",
    "movie_title_map = load_movie_titles_from_csv()\n",
    "\n",
    "def collect_movie_ids():\n",
    "    vals = []\n",
    "    if \"movieid\" in _edges.columns:\n",
    "        vals.extend(_edges[\"movieid\"].dropna().astype(str).tolist())\n",
    "    if 'sw_lines' in globals() and \"movieid\" in sw_lines.columns:\n",
    "        vals.extend(sw_lines[\"movieid\"].dropna().astype(str).tolist())\n",
    "    vals = sorted(sorted(set(vals)), key=natural_key)\n",
    "    return vals\n",
    "\n",
    "movie_ids = collect_movie_ids()\n",
    "\n",
    "# if no titles, just use IDs\n",
    "MOVIE_OPTIONS = [{\"label\": \"All (Trilogy)\", \"value\": \"all\"}] + [\n",
    "    {\"label\": movie_title_map.get(mid, mid), \"value\": mid} for mid in movie_ids\n",
    "]\n",
    "\n",
    "\n",
    "# ---------------- Sentiment (lightweight) ----------------\n",
    "POS_WORDS = set(\"good great love hope happy peace rescue freedom victory friend win brave help\".split())\n",
    "NEG_WORDS = set(\"bad hate kill dark fear death loss war attack betray fail enemy angry\".split())\n",
    "\n",
    "def tiny_sent_score(text: str) -> int:\n",
    "    t = re.findall(r\"[a-z']+\", str(text).lower())\n",
    "    pos = sum(w in POS_WORDS for w in t)\n",
    "    neg = sum(w in NEG_WORDS for w in t)\n",
    "    return 1 if pos>neg else (-1 if neg>pos else 0)\n",
    "\n",
    "def compute_sentiment_counts(lines_df: pd.DataFrame) -> dict:\n",
    "    if lines_df.empty: \n",
    "        return {\"pos\":0,\"neg\":0,\"neu\":0}\n",
    "    col = None\n",
    "    for c in [\"sentiment\",\"sent\",\"polarity_label\"]:\n",
    "        if c in lines_df.columns:\n",
    "            col = c; break\n",
    "    if col is None:\n",
    "        vals = lines_df[\"text\"].astype(str).map(tiny_sent_score)\n",
    "    else:\n",
    "        vals = lines_df[col].astype(int).clip(-1,1)\n",
    "    return {\n",
    "        \"pos\": int((vals== 1).sum()),\n",
    "        \"neg\": int((vals==-1).sum()),\n",
    "        \"neu\": int((vals== 0).sum())\n",
    "    }\n",
    "\n",
    "# collect faction colors\n",
    "def build_faction_color_map():\n",
    "    facs = sorted({str(v.get(\"faction\",\"\")).strip() for v in node_map.values() if v is not None})\n",
    "    facs_l = [f.lower() for f in facs if f]\n",
    "    mapping = {}\n",
    "    used = set()\n",
    "    for f in facs_l:\n",
    "        if f in DEFAULT_FACTION_COLORS:\n",
    "            mapping[f] = DEFAULT_FACTION_COLORS[f]\n",
    "            used.add(DEFAULT_FACTION_COLORS[f])\n",
    "    # color assignment from palette\n",
    "    palette_iter = (c for c in PALETTE if c not in used)\n",
    "    for f in facs_l:\n",
    "        if f not in mapping:\n",
    "            mapping[f] = next(palette_iter, \"#94a3b8\")\n",
    "    return mapping\n",
    "\n",
    "FACTION_COLORS = build_faction_color_map()\n",
    "\n",
    "# -------------- Filter helpers ----------------\n",
    "def filter_edges_by_movie(df: pd.DataFrame, movie_sel):\n",
    "    if movie_sel == \"all\" or \"movieid\" not in df.columns: \n",
    "        return df.copy()\n",
    "    return df[df[\"movieid\"].astype(str) == str(movie_sel)].copy()\n",
    "\n",
    "def build_elements_for_movie(movie_sel):\n",
    "    et = filter_edges_by_movie(_edges, movie_sel)\n",
    "    keep_ids = set(et[\"src\"].tolist() + et[\"dst\"].tolist())\n",
    "    if et.empty:\n",
    "        w_min = w_max = 1\n",
    "    else:\n",
    "        w_min = int(et[\"weight\"].min()); w_max = int(et[\"weight\"].max())\n",
    "        w_min = max(1, w_min); w_max = max(w_min, w_max)\n",
    "\n",
    "    elems = []\n",
    "    for kid in keep_ids:\n",
    "        info = node_map[kid]\n",
    "        label = info[\"label\"]\n",
    "        img_name = (AVATAR_DIR / info.get(\"avatar_png\",\"\")).name\n",
    "        fac = str(info.get(\"faction\",\"\")).lower()\n",
    "        color = FACTION_COLORS.get(fac, \"#94a3b8\")\n",
    "        style = {\"border-color\": color}\n",
    "        data  = {\"id\": kid, \"label\": label}\n",
    "        if img_name and (AVATAR_DIR / img_name).exists():\n",
    "            data[\"img\"] = f\"assets/avatars/{img_name}\"\n",
    "        else:\n",
    "            style[\"background-color\"] = \"#999999\"\n",
    "        elems.append({\"data\": data, \"style\": style})\n",
    "\n",
    "    for _, e in et.iterrows():\n",
    "        elems.append({\n",
    "            \"data\": {\"source\": e[\"src\"], \"target\": e[\"dst\"], \"weight\": int(e[\"weight\"]) }\n",
    "        })\n",
    "\n",
    "    stylesheet = [\n",
    "        {\"selector\": \"node\", \"style\": {\n",
    "            \"label\": \"data(label)\",\n",
    "            \"text-opacity\": 0,           \n",
    "            \"width\": 44, \"height\": 44,\n",
    "            \"background-fit\": \"cover\",\n",
    "            \"background-image\": \"data(img)\",\n",
    "            \"color\": \"#fff\",\n",
    "            \"font-size\": 12,\n",
    "            \"text-valign\": \"top\",\n",
    "            \"text-outline-width\": 2,\n",
    "            \"text-outline-color\": \"#000\",\n",
    "            \"border-width\": 3,\n",
    "        }},\n",
    "        {\"selector\": \"edge\", \"style\": {\n",
    "            \"line-color\": \"#6b7280\",\n",
    "            \"width\": f\"mapData(weight, {w_min}, {w_max}, 1, 8)\"\n",
    "        }},\n",
    "        {\"selector\": \".hovered\", \"style\": {\"text-opacity\": 1}},\n",
    "    ]\n",
    "    return elems, stylesheet\n",
    "\n",
    "# -------------- Bar chart helper ----------------\n",
    "def character_bar_for_movie(movie_sel):\n",
    "    if 'sw_lines' not in globals():\n",
    "        return go.Figure().update_layout(template=\"plotly_dark\", height=260, margin=dict(l=20,r=20,t=10,b=30))\n",
    "    df = sw_lines.copy()\n",
    "    if \"movieid\" in df.columns and movie_sel!=\"all\":\n",
    "        df = df[df[\"movieid\"].astype(str) == str(movie_sel)]\n",
    "    if df.empty:\n",
    "        return go.Figure().update_layout(template=\"plotly_dark\", height=260, margin=dict(l=20,r=20,t=10,b=30))\n",
    "    ser = df.groupby(\"character\")[\"text\"].count().sort_values(ascending=False).head(20)\n",
    "    fig = px.bar(ser, orientation=\"v\", labels={\"value\":\"Lines\", \"character\":\"Character\"})\n",
    "    fig.update_layout(template=\"plotly_dark\", height=260, margin=dict(l=20,r=20,t=10,b=30), xaxis_tickangle=-30)\n",
    "    return fig\n",
    "\n",
    "# -------------- Sentiment charts ----------------\n",
    "def sentiment_figs_for(char_key, movie_sel):\n",
    "    if 'sw_lines' not in globals():\n",
    "        return go.Figure(), go.Figure()\n",
    "    df = sw_lines.copy()\n",
    "    df[\"k\"] = df[\"character\"].astype(str).map(norm_key)\n",
    "    if \"movieid\" in df.columns and movie_sel!=\"all\":\n",
    "        df = df[df[\"movieid\"].astype(str) == str(movie_sel)]\n",
    "    df = df[df[\"k\"]==char_key]\n",
    "\n",
    "    counts = compute_sentiment_counts(df)\n",
    "    pie = px.pie(values=[counts[\"pos\"], counts[\"neu\"], counts[\"neg\"]],\n",
    "                 names=[\"Positive\",\"Neutral\",\"Negative\"], hole=0.45)\\\n",
    "            .update_layout(template=\"plotly_dark\", height=260, margin=dict(l=10,r=10,t=10,b=10))\n",
    "\n",
    "    if \"line_num\" in df.columns and not df.empty:\n",
    "        temp = df[[\"line_num\",\"text\"]].sort_values(\"line_num\").copy()\n",
    "        temp[\"s\"] = temp[\"text\"].astype(str).map(tiny_sent_score)\n",
    "        temp[\"ma\"] = temp[\"s\"].rolling(20, min_periods=1).mean()\n",
    "        line = go.Figure()\n",
    "        line.add_trace(go.Scatter(x=temp[\"line_num\"], y=temp[\"ma\"], mode=\"lines\"))\n",
    "        line.update_layout(template=\"plotly_dark\", height=260, margin=dict(l=10,r=10,t=10,b=10),\n",
    "                           yaxis_title=\"Sentiment (rolling)\", xaxis_title=\"Line order\")\n",
    "    else:\n",
    "        line = go.Figure().update_layout(template=\"plotly_dark\", height=260, margin=dict(l=10,r=10,t=10,b=10))\n",
    "    return pie, line\n",
    "\n",
    "# -------------- Legends ----------------\n",
    "def legend_block():\n",
    "    # fraction colors\n",
    "    items = []\n",
    "    for fac, col in sorted(FACTION_COLORS.items()):\n",
    "        if not fac: \n",
    "            continue\n",
    "        items.append(html.Div([\n",
    "            html.Span(style={\"display\":\"inline-block\",\"width\":\"12px\",\"height\":\"12px\",\n",
    "                             \"border\":\"2px solid \"+col,\"borderRadius\":\"50%\",\"marginRight\":\"8px\"}),\n",
    "            html.Span(fac.capitalize())\n",
    "        ], style={\"marginRight\":\"16px\",\"display\":\"inline-flex\",\"alignItems\":\"center\"}))\n",
    "    edge_legend = html.Div(\"Edge width = number of dialogues between two characters\", style={\"opacity\":0.8})\n",
    "    return html.Div([\n",
    "        html.Div(items, style={\"display\":\"flex\",\"flexWrap\":\"wrap\",\"gap\":\"10px\",\"marginBottom\":\"6px\"}),\n",
    "        edge_legend\n",
    "    ], style={\"color\":\"#cbd5e1\",\"fontSize\":\"13px\"})\n",
    "\n",
    "# -------------- Dash App ----------------\n",
    "try:\n",
    "    for k, srv in list(jupyter_app._server_threads.items()):\n",
    "        try: srv.kill()\n",
    "        except Exception: pass\n",
    "    jupyter_app._server_threads = {}\n",
    "except Exception: pass\n",
    "\n",
    "def get_free_port():\n",
    "    s = socket.socket(); s.bind(('',0)); p=s.getsockname()[1]; s.close(); return p\n",
    "PORT = get_free_port()\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(\"Movie\", style={\"color\":\"#e5e7eb\",\"fontWeight\":\"600\"}),\n",
    "            dcc.Dropdown(\n",
    "                options=[{\"label\": \"All (Trilogy)\", \"value\": \"all\"}] + \n",
    "                        [{\"label\": movie_title_map.get(mid, mid), \"value\": mid} for mid in movie_ids],\n",
    "                value=\"all\", id=\"movie_dd\", clearable=False,\n",
    "                style={\"backgroundColor\":\"#111827\",\"color\":\"#111827\"}\n",
    "            )\n",
    "        ], style={\"width\":\"360px\",\"marginRight\":\"16px\"}),\n",
    "        html.Div(legend_block(), style={\"flex\":\"1\"})\n",
    "    ], style={\"display\":\"flex\",\"alignItems\":\"center\",\"gap\":\"12px\",\"padding\":\"8px 12px\"}),\n",
    "\n",
    "    cyto.Cytoscape(\n",
    "        id=\"cy\",\n",
    "        elements=[],\n",
    "        stylesheet=[],\n",
    "        layout={\"name\": \"cose\", \"randomize\": True, \"idealEdgeLength\": 120, \"nodeOverlap\": 10},\n",
    "        style={\"width\":\"100%\",\"height\":\"520px\",\"backgroundColor\":BG_COLOR},\n",
    "        minZoom=0.2, maxZoom=2.5\n",
    "    ),\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.H4(\"Character Sentiment\", style={\"color\":\"#e5e7eb\",\"margin\":\"6px 0\"}),\n",
    "            html.Div(id=\"char_name\", style={\"color\":\"#93c5fd\",\"marginBottom\":\"6px\"}),\n",
    "            html.Div([\n",
    "                dcc.Graph(id=\"sent_pie\", figure=go.Figure(), config={\"displayModeBar\": False}),\n",
    "                dcc.Graph(id=\"sent_line\", figure=go.Figure(), config={\"displayModeBar\": False})\n",
    "            ], style={\"display\":\"grid\",\"gridTemplateColumns\":\"1fr 1fr\",\"gap\":\"8px\"})\n",
    "        ], style={\"flex\":\"1\",\"padding\":\"0 12px\"}),\n",
    "\n",
    "        html.Div([\n",
    "            html.H4(\"Lines per Character (selected movie)\", style={\"color\":\"#e5e7eb\",\"margin\":\"6px 0\"}),\n",
    "            dcc.Graph(id=\"bar_lines\", figure=go.Figure(), config={\"displayModeBar\": False})\n",
    "        ], style={\"flex\":\"1\",\"padding\":\"0 12px\"})\n",
    "    ], style={\"display\":\"flex\",\"gap\":\"12px\",\"padding\":\"6px 0\"})\n",
    "], style={\"fontFamily\":\"Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif\"})\n",
    "\n",
    "# ----------- Callbacks ----------------\n",
    "@app.callback(\n",
    "    Output(\"cy\",\"elements\"),\n",
    "    Output(\"cy\",\"stylesheet\"),\n",
    "    Input(\"movie_dd\",\"value\")\n",
    ")\n",
    "def refresh_graph(movie_sel):\n",
    "    elems, stylesheet = build_elements_for_movie(movie_sel)\n",
    "    return elems, stylesheet\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"cy\",\"stylesheet\", allow_duplicate=True),\n",
    "    Input(\"cy\",\"mouseoverNodeData\"),\n",
    "    State(\"cy\",\"stylesheet\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def hover_label(node_data, cur_styles):\n",
    "    base = [s for s in cur_styles if s.get(\"selector\") != \"node.hovered\"]\n",
    "    if node_data and \"id\" in node_data:\n",
    "        return base + [{\"selector\": f'node[id = \"{node_data[\"id\"]}\"]', \"style\": {\"text-opacity\": 1}, \"classes\": \"hovered\"}]\n",
    "    return base\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"char_name\",\"children\"),\n",
    "    Output(\"sent_pie\",\"figure\"),\n",
    "    Output(\"sent_line\",\"figure\"),\n",
    "    Input(\"cy\",\"tapNodeData\"),\n",
    "    State(\"movie_dd\",\"value\")\n",
    ")\n",
    "def on_tap(node_data, movie_sel):\n",
    "    if not node_data:\n",
    "        return \"Click a character node...\", go.Figure(), go.Figure()\n",
    "    kid = node_data[\"id\"]\n",
    "    label = node_map.get(kid, {}).get(\"label\", kid)\n",
    "    pie, line = sentiment_figs_for(kid, movie_sel)\n",
    "    return f\"{label}\", pie, line\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"bar_lines\",\"figure\"),\n",
    "    Input(\"movie_dd\",\"value\")\n",
    ")\n",
    "def on_movie_change(movie_sel):\n",
    "    return character_bar_for_movie(movie_sel)\n",
    "\n",
    "print(f\"[INFO] factions (unique): {sorted({str(v.get('faction','')) for v in node_map.values()})}\")\n",
    "print(f\"[INFO] movie_ids: {movie_ids} (titles available: {len(movie_title_map)})\")\n",
    "print(f\"Running at http://127.0.0.1:{PORT}\")\n",
    "app.run_server(mode=\"external\", host=\"127.0.0.1\", port=PORT, debug=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starwars-net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
